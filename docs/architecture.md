AiScoPre 世界杯 AI 预测系统架构说明
==================================

本项目是在你给出的架构思路基础上，做了一版**可落地、可运行的精简实现**，同时保留后续向高性能 C++/ONNX + Kubernetes 架构演进的空间。

本说明分为：

1. 整体架构概览  
2. 微服务划分与职责  
3. 技术选型与简化策略  
4. 运行方式（本地 Demo）  
5. 后续演进与优化建议  

--------------------------------

1. 整体架构概览
----------------

目标：构建一个可扩展的世界杯比赛结果预测系统，支持：

- 按比赛查询胜/平/负概率、比分区间等预测结果  
- 根据比赛实时事件（进球、红牌等）刷新预测  
- 未来可以替换为高性能 C++/ONNX Runtime 推理服务  

本仓库中提供的是一个**以 Python + gRPC 为主的开发版架构**：

- 易于启动与修改，适合算法快速迭代  
- 接口层和数据结构通过 `.proto` 固化，方便后续直接用 C++/Go 重写关键服务  
- 实现了一个端到端可跑通的 Demo：从赛事/球队数据到特征工程到模型推理再到预测聚合  

部署形态（开发版）：

- 单个代码仓库（mono-repo）  
- 多个独立 gRPC 服务进程，通过端口互相调用  
- 提供一个简单的 HTTP 网关，方便前端或手工调试  

--------------------------------

2. 微服务划分与职责
--------------------

目前实现的核心服务（都在 `services/` 目录下）：

1. 赛事服务 `match_service`  
   - 维护比赛列表、比赛基础信息（时间、球队、阶段等）  
   - 暴露查询比赛列表/单场比赛的接口  
   - 支持推送比赛事件（进球、红黄牌等），供预测刷新使用（当前实现为直接 gRPC 调用；生产环境可通过 Kafka）  

2. 球队服务 `team_service`  
   - 维护球队基础信息、简单统计（积分、近期战绩等）  
   - 暴露按 ID 或按名称查询球队数据的接口  

3. 用户服务 `user_service`  
   - 负责用户注册/登录（简单版本使用内存或文件存储）  
   - 记录用户的预测历史（比赛、预测结果、时间）  

4. 特征工程服务 `feature_service`  
   - 核心职责：把原始业务数据（赛事信息、球队统计、赔率等）转换为模型输入向量  
   - 当前 Demo 中使用规则特征：如主客队 Elo、进攻/防守评分、比赛阶段等  
   - 暴露接口：`BuildFeatures(match_id)`，内部通过 gRPC 调用赛事服务 / 球队服务获取原始数据  

5. 模型服务 `model_service`  
   - 封装具体的 AI/算法模型，可后续替换为 ONNX Runtime / GPU 推理  
   - 当前 Demo 使用一个简单的逻辑回归风格的手写公式，避免依赖复杂 ML 框架，也更容易直接运行  
   - 暴露接口：`PredictOutcome(feature_vector)`，输出胜/平/负概率等  

6. 预测服务 `prediction_service`  
   - 聚合层服务，对外暴露「一站式预测 API」  
   - 内部调用：赛事服务 + 特征服务 + 模型服务，组合出完整预测结果  
   - 提供两类接口：  
     - 简单预测：一次性返回当前预测结果  
     - 流式预测：使用 gRPC Server Streaming，在比赛事件变化时推送最新预测（Demo 中用定时轮询和内存事件总线模拟）  
   - 实现了一个简单的 LRU 内存缓存，后续可替换为 Redis Cluster  

7. 网关服务 `gateway`（可选，但本仓库提供实现）  
   - 基于 FastAPI 的 HTTP + JSON 网关  
   - 前端只需要调用 HTTP API，网关内部再调用 gRPC 预测服务  

--------------------------------

3. 技术选型与简化策略
----------------------

你原本的设计：C++ + gRPC + ONNX Runtime + Redis Cluster + Kafka + PostgreSQL/ClickHouse + Kubernetes HPA。  
为了能在一个仓库内快速跑通 Demo，我们做了如下**分层简化**：

1. 语言与运行时  
   - 开发版全部使用 Python 实现 gRPC 服务，便于快速修改和演示。  
   - `.proto` 文件中已经约定了统一的消息与服务接口，未来迁移到 C++ 只需要重新生成 stub 并实现相同接口即可。  

2. 存储层  
   - Demo 中所有服务默认使用内存存储（进程内字典），避免本地启动还需要安装数据库。  
   - 通过抽象接口预留出替换 PostgreSQL/Redis 的空间：  
     - 比赛/球队数据适合落 PostgreSQL  
     - 热点预测结果、比赛进行中的状态适合放在 Redis  

3. 消息队列与事件流  
   - Demo 中的实时预测通过定时轮询 + 内存事件列表模拟。  
   - 在架构层面保留了 `MatchEvent` 等消息结构，后续可以直接映射到 Kafka Topic。  

4. 推理引擎  
   - 当前版本用一个手写的简易函数代替真正的模型推理（避免依赖 onnxruntime / torch 等三方库）。  
   - 接口上统一使用：`FeatureVector -> PredictionResult`，可以直接替换为 ONNX Runtime 调用。  

5. 部署与伸缩  
   - Demo 提供 `docker-compose.yml` 方便在本地一次性启动所有服务。  
   - 文档中给出示例性的 Kubernetes 部署与 HPA 配置（YAML 草稿），方便未来迁移到 K8s。  

--------------------------------

4. 运行方式（本地 Demo）
-------------------------

前置环境（建议）：  

- Python 3.10+  
- `pip` 可用  
- Docker / Docker Compose（可选，用于一键启动）  

基础步骤：

1. 安装依赖

   ```bash
   pip install -r requirements.txt
   ```

2. 生成 gRPC 代码（如需要重新生成）

   ```bash
   ./scripts/gen_protos.sh
   ```

3. 启动所有服务（本地多进程版本）

   ```bash
   python scripts/start_all.py
   ```

4. 调用网关 HTTP 接口进行预测

   ```bash
   curl "http://localhost:8000/predict?match_id=1"
   ```

   返回示例（简化）：

   ```json
   {
     "match_id": "1",
     "home_team": "Argentina",
     "away_team": "France",
     "probabilities": {
       "home_win": 0.42,
       "draw": 0.28,
       "away_win": 0.30
     }
   }
   ```

--------------------------------

5. 后续演进与优化建议
----------------------

基于当前可运行 Demo，可以按如下路线逐步演进到你最初设想的高性能架构：

1. 推理服务升级  
   - 在 `model_service` 中接入 ONNX Runtime，加载训练好的模型。  
   - 增加批量预测接口，配合 gRPC streaming，在高并发情况下减少模型调用开销。  

2. 存储层落地  
   - 将赛事和球队数据持久化到 PostgreSQL；  
   - 使用 Redis 缓存热点比赛的预测结果和状态，替换当前的内存 LRU 缓存。  

3. 事件驱动实时预测  
   - 将比赛事件写入 Kafka Topic；  
   - 新增一个独立的 `prediction_updater` 服务订阅事件，调用 `model_service` 刷新预测并写入 Redis。  
   - 预测服务读取 Redis 中的最新结果，并通过 gRPC 流式接口推送给客户端。  

4. 性能与伸缩  
   - 将 `prediction_service` 和 `model_service` 重写为 C++ 实现，部署到 Kubernetes 中，使用 HPA 按 CPU/QPS 扩缩容。  
   - 前面这套 Python 实现依然可以作为：  
     - 本地开发/调试环境；  
     - 特征工程和模型实验平台。  

5. 观测与治理  
   - 统一接入日志、Tracing（如 OpenTelemetry）、Metrics（Prometheus），实现对每个预测请求的端到端观测。  
   - 增加灰度发布、AB Test 能力，用于新模型上线评估。  

--------------------------------

6. 数据采集与可视化
-------------------

**合规数据采集**  

- `scripts/scrape_wc2026.py` 提供安全爬取示例：  
  - 运行前需使用 `--allow-domain` 显式声明目标域名；  
  - 抓取前读取 robots.txt，如被禁止则直接退出；  
  - 自定义 `User-Agent` + 请求间隔，便于目标站点定位或节流；  
  - 默认读取 `data/sample_wc2026_source.html`，确保在离线情况下也能验证解析逻辑。  
- 产物是结构化 JSON（默认写入 `data/latest_wc2026_info.json`），包括主办信息及赔率列表；  
- 网关通过 `WC2026_DATA_PATH` 加载 JSON 数据，并暴露 `/wc2026` 与 `/wc2026/reload` 接口。

**前端可视化**  

- `web/index.html` 是一个纯静态单页，FastAPI 网关在 `/` 提供服务；  
- 功能：  
  - 输入比赛 ID，调用 `/predict`，以 Chart.js 呈现主胜/平/客胜概率；  
  - 调用 `/wc2026` 显示赛事元数据与最新赔率表；  
  - 页脚提示数据来源和合规要求。  
- 前端完全基于浏览器 `fetch`，无需额外构建步骤。

--------------------------------

接下来可以从代码入手，先在本地跑起来 Demo，再根据需要逐步替换单个服务为 C++/Go 等高性能版本。
